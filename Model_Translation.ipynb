{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJsoBe5xbWG8eb52YrYEVP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "english_text = ['Hello, how are you?', 'What time is it?', 'Can you help me, please?', 'How much does it cost?', 'Where is the nearest hospital?', 'Where is he?']\n",
        "indonesian_text = ['Halo apa kabarmu?', 'Jam berapa?', 'Bisakah Anda menolong saya?', 'Harganya berapa?', 'Dimana rumah sakit terdekat?', 'Dimana dia?']\n",
        "\n",
        "# Tokenize the data\n",
        "english_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "english_tokenizer.fit_on_texts(english_text)\n",
        "english_sequences = english_tokenizer.texts_to_sequences(english_text)\n",
        "english_padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(english_sequences, padding='post')\n",
        "\n",
        "indonesian_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "indonesian_tokenizer.fit_on_texts(indonesian_text)\n",
        "indonesian_sequences = indonesian_tokenizer.texts_to_sequences(indonesian_text)\n",
        "indonesian_padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(indonesian_sequences, padding='post')\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(english_tokenizer.word_index)+1, 256),\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.RepeatVector(len(indonesian_padded_sequences[0])),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(indonesian_tokenizer.word_index)+1, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "model.fit(english_padded_sequences, indonesian_padded_sequences, batch_size=64, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Save the model\n",
        "model.save('english_to_indonesian_translation_model.h5')\n",
        "\n",
        "# Generate translations\n",
        "def translate(sentence):\n",
        "    sentence_sequence = english_tokenizer.texts_to_sequences([sentence])\n",
        "    sentence_padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sentence_sequence, padding='post', maxlen=len(english_padded_sequences[0]))\n",
        "    prediction = model.predict(sentence_padded_sequence)[0]\n",
        "    predicted_sequence = [np.argmax(token) for token in prediction]\n",
        "    translation = indonesian_tokenizer.sequences_to_texts([predicted_sequence])\n",
        "    return translation[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvl2nkspLxAB",
        "outputId": "19e3019e-921e-4369-d7be-419d35d8d05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.7708 - val_loss: 2.7623\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 2.7534 - val_loss: 2.7516\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.7324 - val_loss: 2.7368\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.7040 - val_loss: 2.7156\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.6641 - val_loss: 2.6849\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.6070 - val_loss: 2.6415\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.5250 - val_loss: 2.5811\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.4086 - val_loss: 2.5014\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2515 - val_loss: 2.4116\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.0747 - val_loss: 2.3615\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 1.9692 - val_loss: 2.4380\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 1.9963 - val_loss: 2.5663\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 2.0157 - val_loss: 2.6298\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 1.9593 - val_loss: 2.6266\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.8621 - val_loss: 2.5962\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.7664 - val_loss: 2.5714\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 1.6945 - val_loss: 2.5657\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 1.6466 - val_loss: 2.5783\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.6098 - val_loss: 2.6044\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.5723 - val_loss: 2.6422\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.5301 - val_loss: 2.6950\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.4839 - val_loss: 2.7704\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.4360 - val_loss: 2.8791\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.3875 - val_loss: 3.0313\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.3406 - val_loss: 3.2312\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.2990 - val_loss: 3.4714\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.2648 - val_loss: 3.7297\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.2344 - val_loss: 3.9752\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 1.2005 - val_loss: 4.1815\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.1574 - val_loss: 4.3367\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.1050 - val_loss: 4.4453\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.0491 - val_loss: 4.5243\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9978 - val_loss: 4.5961\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.9552 - val_loss: 4.6800\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.9153 - val_loss: 4.7861\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.8690 - val_loss: 4.9165\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.8155 - val_loss: 5.0664\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.7630 - val_loss: 5.2223\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.7188 - val_loss: 5.3672\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6797 - val_loss: 5.4915\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.6395 - val_loss: 5.5974\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.5966 - val_loss: 5.6751\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.5537 - val_loss: 5.7414\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.5151 - val_loss: 5.8294\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.4838 - val_loss: 5.9487\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.4564 - val_loss: 6.1047\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.4255 - val_loss: 6.2968\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3904 - val_loss: 6.5181\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.3574 - val_loss: 6.7565\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.3289 - val_loss: 6.9987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'where is he'\n",
        "print('Input Text:', translate(input_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHYBLrtDL_yI",
        "outputId": "a287d584-a778-4d53-eb87-61d5d2629f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Input Text: jam apa\n"
          ]
        }
      ]
    }
  ]
}